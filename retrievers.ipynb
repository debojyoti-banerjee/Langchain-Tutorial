{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b9c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3827fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load env variables\n",
    "load_dotenv()\n",
    "#Making model\n",
    "llm=HuggingFaceEndpoint(repo_id=\"MiniMaxAI/MiniMax-M1-80k\",task=\"text-generation\")\n",
    "model=ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5a873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DEBOJYOTI\\OneDrive\\Desktop\\Study\\Langchain-Tutorial\\langchainVenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Building embedding model\n",
    "embedding=HuggingFaceEndpointEmbeddings(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43745db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DEBOJYOTI\\AppData\\Local\\Temp\\ipykernel_5196\\3576844061.py:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store=Chroma(embedding_function=embedding,persist_directory=\"Chroma_db\",collection_name=\"sample_2\")\n"
     ]
    }
   ],
   "source": [
    "vector_store=Chroma(embedding_function=embedding,persist_directory=\"Chroma_db\",collection_name=\"sample_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5dd93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(\"Btech_Project.pdf\")\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac9d9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['94d973d9-dd81-4326-a541-987a56717de1',\n",
       " 'fdf174dd-e33e-40f9-9eec-0bfd7307f637',\n",
       " '700f0331-807b-4a31-984a-9b291d994b72',\n",
       " '0c309062-aa6a-4ac1-a974-56ad4503d8f7',\n",
       " 'badd3c68-e8d3-4782-b139-def6058b0178',\n",
       " 'ea466f2f-7596-42c5-a836-2c8d98e9a0b3',\n",
       " 'd1f6bf5d-faae-40f6-b399-2829d3616df2',\n",
       " '03303852-44c3-4ac4-b5a5-86f828f0c664',\n",
       " '1fcf3337-4824-407e-bafa-2ea1216dadc8',\n",
       " '5190bb3c-678c-4db4-81e4-926cd82a4bf5',\n",
       " '5d1fb6f9-92df-4d6a-ad3a-097d6a0c71a1',\n",
       " '0931d600-59ce-48d8-837b-32af3a1bea4c',\n",
       " 'e2131363-38df-4063-a0d3-a704ab419453',\n",
       " '2bd22d10-9c01-4cde-9320-d5db75f3a173']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386414f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":3,\"lambda_mult\":0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc099c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'trapped': '/False', 'creationdate': '2025-04-28T13:47:29+00:00', 'source': 'Btech_Project.pdf', 'creator': 'TeX', 'page': 1, 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'moddate': '2025-04-28T13:47:29+00:00', 'page_label': '2', 'producer': 'pdfTeX-1.40.26', 'total_pages': 14}, page_content='The Hurst Exponent\\nThe Hurst exponent (H) is a statistical parameter that is employed to describe the\\nlong-memory of time series data. The Hurst exponent gives the amount of persistence or\\nanti-persistence present in the data. The Hurst exponent can lie within the interval from\\n0 to 1, and it informs about the type of the time series:\\n• H <0.5: Represents an anti-persistent time series. This is a series that, if it is\\nrising at some point, will fall in the future, and vice versa.\\n• H = 0.5: Is a random walk, where the time series has no correlation between the\\npast and the future. This is the behavior of a Brownian motion.\\n• H >0.5: Indicates persistence or trend-following behavior. If the series is going\\nup, it will likely keep going up, and the reverse for declining trends.\\nThe Hurst exponent is used in hydrology, geophysics, economics, and finance to ana-\\nlyze the fractal nature of data and to forecast trends in the future.\\nMultifractal Detrended Fluctuation Analysis (MF-DFA)\\nThe Multifractal Detrended Fluctuation Analysis (MF-DFA)is a detection method\\nfor multifractality in time series data. It is an extension of the standard DFA(Detrended\\nFluctuation Analysis) and is best suited for time series with multifractal and complex\\nstructures.\\nThe MF-DFA method goes through the following steps:\\n1. Detrending: A polynomial fit (typically of order 1 or 2) is subtracted from non-\\noverlapping windows of the time series to eliminate trends in each window.\\n2. Fluctuation Analysis : The detrended time series is analyzed for fluctuations\\nacross a range of scales or window sizes.\\n3. Log-Log Plot: A log-log plot of the fluctuation function is drawn, and the slope\\nof the plot is the value of the Hurst exponent. The MF-DFA technique provides\\nfor the determination of various scaling exponents over various regions and hence\\nis particularly suitable for the analysis of multifractal behavior.\\nThe MF-DFA method is robust against trends and is capable of handling a broad\\nvariety of time series data, even with noise or non-stationary behavior.\\nRescaled Range (R/S) Method\\nThe Rescaled Range (R/S) technique is one of the oldest methods to compute the\\nHurst exponent and is based on the idea of rescaling the range of partial sums of a time\\nseries. The technique is simple and efficient for identifying long-range dependence in a\\ntime series.\\nThe technique includes the following steps:\\n2'), Document(metadata={'moddate': '2025-04-28T13:47:29+00:00', 'page_label': '7', 'source': 'Btech_Project.pdf', 'creator': 'TeX', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'trapped': '/False', 'creationdate': '2025-04-28T13:47:29+00:00', 'total_pages': 14, 'page': 6, 'producer': 'pdfTeX-1.40.26'}, page_content='start = v * scale\\nend = start + scale\\nsegment = Y[start:end]\\nx = np.arange(scale)\\ncoeffs = np.polyfit(x, segment, m)\\nfit = np.polyval(coeffs, x)\\nrms = np.sqrt(np.mean((segment - fit)**2))\\nrms_list.append(rms)\\n# Backward segments\\nfor v in range(0, Ns):\\nstart = N - (v+1)*scale\\nend = start + scale\\nsegment = Y[start:end]\\nx = np.arange(scale)\\ncoeffs = np.polyfit(x, segment, m)\\nfit = np.polyval(coeffs, x)\\nrms = np.sqrt(np.mean((segment - fit)**2))\\nrms_list.append(rms)\\nrms_list = np.array(rms_list)\\n# Calculate fluctuation function\\nif q == 0:\\nFq = np.exp(0.5 * np.mean(np.log(rms_list**2)))\\nelse:\\nFq = (np.mean(rms_list**q))**(1/q)\\nF_s.append(Fq)\\nused_scales.append(scale)\\nlog_scale = np.log2(used_scales)\\n7'), Document(metadata={'creationdate': '2025-04-28T13:47:29+00:00', 'page_label': '14', 'source': 'Btech_Project.pdf', 'moddate': '2025-04-28T13:47:29+00:00', 'creator': 'TeX', 'page': 13, 'total_pages': 14, 'trapped': '/False', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'producer': 'pdfTeX-1.40.26'}, page_content='Observations And Inference\\nSignal 1: The values of Signal 1 exhibit moderate variation across the sequence, with\\nvalues generally ranging from 0.51 to 0.66. Notably, the highest values are concentrated\\naround 0.60-0.62, while the values at the lower end remain between 0.51-0.55. This\\nindicates a relatively stable signal with slight fluctuations.\\nSignal 2: Signal 2 shows relatively consistent values, mostly between 0.37 and 0.42, with\\noccasional slight peaks at 0.41 and 0.42. The variation is minimal compared to Signal 1,\\nwhich suggests this signal is more stable with fewer large fluctuations.\\nSignal 3: Signal 3 fluctuates more significantly, with values ranging from 0.20 to 0.30.\\nThere are higher frequencies of values between 0.22 and 0.26, with notable spikes at 0.29\\nand 0.30. The variability in this signal suggests it might have a more dynamic behavior\\nthan the first two signals.\\nSignal 4: Signal 4 displays values between 0.32 and 0.43, with a slightly higher con-\\ncentration around 0.39 and 0.41. The overall pattern is similar to Signal 2, with small\\ndeviations indicating moderate fluctuations in the signal.\\n14')]\n",
      "The Hurst Exponent\n",
      "The Hurst exponent (H) is a statistical parameter that is employed to describe the\n",
      "long-memory of time series data. The Hurst exponent gives the amount of persistence or\n",
      "anti-persistence present in the data. The Hurst exponent can lie within the interval from\n",
      "0 to 1, and it informs about the type of the time series:\n",
      "• H <0.5: Represents an anti-persistent time series. This is a series that, if it is\n",
      "rising at some point, will fall in the future, and vice versa.\n",
      "• H = 0.5: Is a random walk, where the time series has no correlation between the\n",
      "past and the future. This is the behavior of a Brownian motion.\n",
      "• H >0.5: Indicates persistence or trend-following behavior. If the series is going\n",
      "up, it will likely keep going up, and the reverse for declining trends.\n",
      "The Hurst exponent is used in hydrology, geophysics, economics, and finance to ana-\n",
      "lyze the fractal nature of data and to forecast trends in the future.\n",
      "Multifractal Detrended Fluctuation Analysis (MF-DFA)\n",
      "The Multifractal Detrended Fluctuation Analysis (MF-DFA)is a detection method\n",
      "for multifractality in time series data. It is an extension of the standard DFA(Detrended\n",
      "Fluctuation Analysis) and is best suited for time series with multifractal and complex\n",
      "structures.\n",
      "The MF-DFA method goes through the following steps:\n",
      "1. Detrending: A polynomial fit (typically of order 1 or 2) is subtracted from non-\n",
      "overlapping windows of the time series to eliminate trends in each window.\n",
      "2. Fluctuation Analysis : The detrended time series is analyzed for fluctuations\n",
      "across a range of scales or window sizes.\n",
      "3. Log-Log Plot: A log-log plot of the fluctuation function is drawn, and the slope\n",
      "of the plot is the value of the Hurst exponent. The MF-DFA technique provides\n",
      "for the determination of various scaling exponents over various regions and hence\n",
      "is particularly suitable for the analysis of multifractal behavior.\n",
      "The MF-DFA method is robust against trends and is capable of handling a broad\n",
      "variety of time series data, even with noise or non-stationary behavior.\n",
      "Rescaled Range (R/S) Method\n",
      "The Rescaled Range (R/S) technique is one of the oldest methods to compute the\n",
      "Hurst exponent and is based on the idea of rescaling the range of partial sums of a time\n",
      "series. The technique is simple and efficient for identifying long-range dependence in a\n",
      "time series.\n",
      "The technique includes the following steps:\n",
      "2\n",
      "start = v * scale\n",
      "end = start + scale\n",
      "segment = Y[start:end]\n",
      "x = np.arange(scale)\n",
      "coeffs = np.polyfit(x, segment, m)\n",
      "fit = np.polyval(coeffs, x)\n",
      "rms = np.sqrt(np.mean((segment - fit)**2))\n",
      "rms_list.append(rms)\n",
      "# Backward segments\n",
      "for v in range(0, Ns):\n",
      "start = N - (v+1)*scale\n",
      "end = start + scale\n",
      "segment = Y[start:end]\n",
      "x = np.arange(scale)\n",
      "coeffs = np.polyfit(x, segment, m)\n",
      "fit = np.polyval(coeffs, x)\n",
      "rms = np.sqrt(np.mean((segment - fit)**2))\n",
      "rms_list.append(rms)\n",
      "rms_list = np.array(rms_list)\n",
      "# Calculate fluctuation function\n",
      "if q == 0:\n",
      "Fq = np.exp(0.5 * np.mean(np.log(rms_list**2)))\n",
      "else:\n",
      "Fq = (np.mean(rms_list**q))**(1/q)\n",
      "F_s.append(Fq)\n",
      "used_scales.append(scale)\n",
      "log_scale = np.log2(used_scales)\n",
      "7\n",
      "Observations And Inference\n",
      "Signal 1: The values of Signal 1 exhibit moderate variation across the sequence, with\n",
      "values generally ranging from 0.51 to 0.66. Notably, the highest values are concentrated\n",
      "around 0.60-0.62, while the values at the lower end remain between 0.51-0.55. This\n",
      "indicates a relatively stable signal with slight fluctuations.\n",
      "Signal 2: Signal 2 shows relatively consistent values, mostly between 0.37 and 0.42, with\n",
      "occasional slight peaks at 0.41 and 0.42. The variation is minimal compared to Signal 1,\n",
      "which suggests this signal is more stable with fewer large fluctuations.\n",
      "Signal 3: Signal 3 fluctuates more significantly, with values ranging from 0.20 to 0.30.\n",
      "There are higher frequencies of values between 0.22 and 0.26, with notable spikes at 0.29\n",
      "and 0.30. The variability in this signal suggests it might have a more dynamic behavior\n",
      "than the first two signals.\n",
      "Signal 4: Signal 4 displays values between 0.32 and 0.43, with a slightly higher con-\n",
      "centration around 0.39 and 0.41. The overall pattern is similar to Signal 2, with small\n",
      "deviations indicating moderate fluctuations in the signal.\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "result=retriever.invoke(\"what is hurst exponent\")\n",
    "print(result)\n",
    "for i in result:\n",
    "    print(i.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccb2b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=MultiQueryRetriever.from_llm(retriever=vector_store.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":3,\"lambda_mult\":0.2}),llm=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f4a69c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R/S Method - Step-by-Step Description\n",
      "Input Time Series:\n",
      "• The process starts by accepting a time series signal as input. The signal usually\n",
      "indicates a collection of data points recorded over time.\n",
      "Setting the Scales:\n",
      "• The process establishes a range of scales on which the analysis is done. These ranges\n",
      "from a minimum scale (16) to a maximum scale (N // 4, where N is the size of the\n",
      "signal).\n",
      "• A total of 20 scales are selected logarithmically between these limits. This log-\n",
      "arithmic selection allows for a wide range of scales to be tested, capturing both\n",
      "short-term and long-term behavior in the data.\n",
      "Dividing the Signal into Segments:\n",
      "• For every scale, the signal is broken down into non-overlapping segments of corre-\n",
      "sponding length. At scale 16, for instance, the signal is divided into segments of 16\n",
      "units of length. For each segment, the following computations are performed.\n",
      "Detrending the Data:\n",
      "• For every segment, the segment mean is computed and subtracted from every data\n",
      "point within the segment. This step brings the segment to zero and makes it simple\n",
      "to examine the fluctuations around the mean.\n",
      "Cumulative Sum:\n",
      "• The sum of the mean-adjusted segment is then accumulated. The cumulative sum\n",
      "is the running total of deviations from the mean, which can be used to determine\n",
      "the overall trend and fluctuations in the segment.\n",
      "Determining the Range (R):\n",
      "• The range (R) of the cumulative sum is calculated by determining the highest and\n",
      "lowest values of the cumulative sum within each segment. The range is obtained\n",
      "by subtracting the lowest from the highest value, which is a measure of the level of\n",
      "changes in the segment.\n",
      "Calculating the Standard Deviation (S):\n",
      "• The standard deviation (S) of the initial segment is calculated. The standard\n",
      "deviation calculates how much the points vary from the mean.\n",
      "Rescaled Range (R/S):\n",
      "• The rescaled range (R/S) can be determined as a ratio between the range (R) and\n",
      "the standard deviation (S) of each segment. The resultant ratio is a measure of\n",
      "normalized fluctuation for the segment.\n",
      "Average Rescaled Range:\n",
      "9\n",
      "The Hurst Exponent\n",
      "The Hurst exponent (H) is a statistical parameter that is employed to describe the\n",
      "long-memory of time series data. The Hurst exponent gives the amount of persistence or\n",
      "anti-persistence present in the data. The Hurst exponent can lie within the interval from\n",
      "0 to 1, and it informs about the type of the time series:\n",
      "• H <0.5: Represents an anti-persistent time series. This is a series that, if it is\n",
      "rising at some point, will fall in the future, and vice versa.\n",
      "• H = 0.5: Is a random walk, where the time series has no correlation between the\n",
      "past and the future. This is the behavior of a Brownian motion.\n",
      "• H >0.5: Indicates persistence or trend-following behavior. If the series is going\n",
      "up, it will likely keep going up, and the reverse for declining trends.\n",
      "The Hurst exponent is used in hydrology, geophysics, economics, and finance to ana-\n",
      "lyze the fractal nature of data and to forecast trends in the future.\n",
      "Multifractal Detrended Fluctuation Analysis (MF-DFA)\n",
      "The Multifractal Detrended Fluctuation Analysis (MF-DFA)is a detection method\n",
      "for multifractality in time series data. It is an extension of the standard DFA(Detrended\n",
      "Fluctuation Analysis) and is best suited for time series with multifractal and complex\n",
      "structures.\n",
      "The MF-DFA method goes through the following steps:\n",
      "1. Detrending: A polynomial fit (typically of order 1 or 2) is subtracted from non-\n",
      "overlapping windows of the time series to eliminate trends in each window.\n",
      "2. Fluctuation Analysis : The detrended time series is analyzed for fluctuations\n",
      "across a range of scales or window sizes.\n",
      "3. Log-Log Plot: A log-log plot of the fluctuation function is drawn, and the slope\n",
      "of the plot is the value of the Hurst exponent. The MF-DFA technique provides\n",
      "for the determination of various scaling exponents over various regions and hence\n",
      "is particularly suitable for the analysis of multifractal behavior.\n",
      "The MF-DFA method is robust against trends and is capable of handling a broad\n",
      "variety of time series data, even with noise or non-stationary behavior.\n",
      "Rescaled Range (R/S) Method\n",
      "The Rescaled Range (R/S) technique is one of the oldest methods to compute the\n",
      "Hurst exponent and is based on the idea of rescaling the range of partial sums of a time\n",
      "series. The technique is simple and efficient for identifying long-range dependence in a\n",
      "time series.\n",
      "The technique includes the following steps:\n",
      "2\n",
      "Observations And Inference\n",
      "Signal 1: The values of Signal 1 exhibit moderate variation across the sequence, with\n",
      "values generally ranging from 0.51 to 0.66. Notably, the highest values are concentrated\n",
      "around 0.60-0.62, while the values at the lower end remain between 0.51-0.55. This\n",
      "indicates a relatively stable signal with slight fluctuations.\n",
      "Signal 2: Signal 2 shows relatively consistent values, mostly between 0.37 and 0.42, with\n",
      "occasional slight peaks at 0.41 and 0.42. The variation is minimal compared to Signal 1,\n",
      "which suggests this signal is more stable with fewer large fluctuations.\n",
      "Signal 3: Signal 3 fluctuates more significantly, with values ranging from 0.20 to 0.30.\n",
      "There are higher frequencies of values between 0.22 and 0.26, with notable spikes at 0.29\n",
      "and 0.30. The variability in this signal suggests it might have a more dynamic behavior\n",
      "than the first two signals.\n",
      "Signal 4: Signal 4 displays values between 0.32 and 0.43, with a slightly higher con-\n",
      "centration around 0.39 and 0.41. The overall pattern is similar to Signal 2, with small\n",
      "deviations indicating moderate fluctuations in the signal.\n",
      "14\n",
      "Introduction To Hurst Exponent\n",
      "The Hurst exponent, so named after British hydrologist Harold Edwin Hurst, is a\n",
      "primary measure for the study of the long-term memory and self-similarity of time series\n",
      "data. It is a crucial measure across numerous fields such as geophysics, economics, finance,\n",
      "and even environmental science, which offers insights into the persistence, trend, and\n",
      "volatility of the data over time.\n",
      "In this project, the Hurst exponent is determined through two methods: the Mul-\n",
      "tifractal Detrended Fluctuation Analysis (MF-DFA) and the Rescaled Range\n",
      "(R/S) method. The two methods are commonly used to determine the fractality of a\n",
      "time series, with the Hurst exponent determining if the time series is long-range depen-\n",
      "dent or random.\n",
      "• MF-DFA is a technique that specializes in studying the multifractal behavior of\n",
      "time series through detrending and investigating the fluctuations across scales. The\n",
      "technique is especially handy when dealing with data that shows multifractality or\n",
      "intricate self-similar structures.\n",
      "• R/S method , however, is a more straightforward method founded on rescaling\n",
      "the range of partial sums of the time series. It is a straightforward estimate of the\n",
      "Hurst exponent and is extensively employed in time series data with long-range\n",
      "dependencies.\n",
      "The objective of this project is to compute the Hurst exponent employing both ap-\n",
      "proaches and compare them. In doing this, we are able to ensure the validity and accuracy\n",
      "of these approaches in determining the Hurst exponent in real-world time series data.\n",
      "Subsequent sections will outline the theory behind the Hurst exponent, describe how\n",
      "each approach used to compute the Hurst exponent is done, and show the outcomes\n",
      "derived using MF-DFA and the R/S method.\n",
      "1\n",
      "start = v * scale\n",
      "end = start + scale\n",
      "segment = Y[start:end]\n",
      "x = np.arange(scale)\n",
      "coeffs = np.polyfit(x, segment, m)\n",
      "fit = np.polyval(coeffs, x)\n",
      "rms = np.sqrt(np.mean((segment - fit)**2))\n",
      "rms_list.append(rms)\n",
      "# Backward segments\n",
      "for v in range(0, Ns):\n",
      "start = N - (v+1)*scale\n",
      "end = start + scale\n",
      "segment = Y[start:end]\n",
      "x = np.arange(scale)\n",
      "coeffs = np.polyfit(x, segment, m)\n",
      "fit = np.polyval(coeffs, x)\n",
      "rms = np.sqrt(np.mean((segment - fit)**2))\n",
      "rms_list.append(rms)\n",
      "rms_list = np.array(rms_list)\n",
      "# Calculate fluctuation function\n",
      "if q == 0:\n",
      "Fq = np.exp(0.5 * np.mean(np.log(rms_list**2)))\n",
      "else:\n",
      "Fq = (np.mean(rms_list**q))**(1/q)\n",
      "F_s.append(Fq)\n",
      "used_scales.append(scale)\n",
      "log_scale = np.log2(used_scales)\n",
      "7\n",
      "MF-DFA Method - Step-by-Step Explanation\n",
      "Input Time Series:\n",
      "• Receiving the time series data (signal) as input is the first step. The signal usually\n",
      "corresponds to a series of observations over time.\n",
      "Calculating the Profile:\n",
      "• The time series data is shifted by subtracting its mean value. This is performed to\n",
      "center the data around zero. Then, the cumulative sum of the mean-shifted data\n",
      "is calculated, which is known as the profile of the signal. This profile assists in\n",
      "capturing the overall trend or behavior of the signal over time.\n",
      "Defining the Scales:\n",
      "• To process the data at various levels, we specify a number of scales. A scale is\n",
      "basically a window size for which the data will be processed. Here, the scales are\n",
      "selected logarithmically from a minimum scale to a maximum scale. This enables\n",
      "the method to pick up fine and coarse variations in the data. A fixed number of\n",
      "scales is chosen between these boundaries to compare various time window sizes.\n",
      "Segmenting the Signal:\n",
      "• The signal is split into non-overlapping segments for every scale. The number of\n",
      "segments varies with the scale and the overall length of the signal. Each segment\n",
      "corresponds to a portion of the signal that will be examined for fluctuations and\n",
      "trends.\n",
      "Detrending the Data in Each Segment:\n",
      "• A detrending is performed in each segment. This is done by fitting a straight\n",
      "line (linear trend) to the segment’s data. The linear fit is then subtracted from\n",
      "the segment, and the root mean square (RMS) of the difference (residuals) is\n",
      "computed. The RMS value measures the fluctuation (or deviation from the trend)\n",
      "for the segment. RMS error assists in quantifying the level of randomness or noise\n",
      "within the segment with respect to the fitted trend.\n",
      "Calculating the Fluctuation Function:\n",
      "• After the RMS values for all segments are computed, a fluctuation function\n",
      "is obtained. This function gives a summary of the fluctuation behavior at each\n",
      "scale. If a particular value of q is chosen, the fluctuation function is obtained by\n",
      "averaging the RMS values to the power of q. In certain situations, when q = 0 ,\n",
      "the logarithmic mean of the RMS values squared is employed instead.\n",
      "Logarithmic Transformation:\n",
      "• To more easily visualize the scaling relationship between the fluctuation function\n",
      "and the scale, the values of the scale and the fluctuation function are converted to\n",
      "logarithms. This converts the data into a format where a linear relationship can be\n",
      "determined, making it simpler to estimate the scaling exponent.\n",
      "Performing Linear Regression:\n",
      "4\n",
      "log_Fq = np.log2(F_s)\n",
      "slope, _, _, _, _ = stats.linregress(log_scale, log_Fq)\n",
      "if slope-1 < 0:\n",
      "return slope\n",
      "else:\n",
      "return slope-1\n",
      "# Example usage\n",
      "folder_path = \"input_signal\"\n",
      "text_files = glob.glob(os.path.join(folder_path, \"*.txt\"))\n",
      "for file_path in text_files:\n",
      "signal_req = np.loadtxt(file_path)\n",
      "hurst = calculate_hurst_exponent(signal_req)\n",
      "print(\"Hurst Exponent:\", hurst)\n",
      "with open(\"output_signal.txt\", \"a\") as f:\n",
      "f.write(f\"Hurst Exponent: {hurst}\\n\")\n",
      "8\n",
      "Results\n",
      "The Hurst exponents were calculated for four different signals using two different\n",
      "methods: Multifractal Detrended Fluctuation Analysis (MF-DFA) and Rescaled Range\n",
      "(R/S) analysis. Each signal was divided into multiple segments, and for each segment,\n",
      "the Hurst exponent was computed.\n",
      "MF-DFA Method\n",
      "Signal 1:\n",
      "• Hurst Values: 0.59, 0.52, 0.54, 0.55, 0.59, 0.60, 0.55, 0.53, 0.53, 0.62, 0.66, 0.58,\n",
      "0.53, 0.54, 0.53, 0.55, 0.53, 0.52, 0.57, 0.56, 0.54, 0.61, 0.62, 0.54, 0.57, 0.52, 0.56,\n",
      "0.58, 0.60, 0.56, 0.51, 0.52, 0.57, 0.57, 0.57, 0.55, 0.55, 0.52, 0.51\n",
      "Signal 2:\n",
      "• Hurst Values: 0.39, 0.39, 0.41, 0.41, 0.38, 0.38, 0.40, 0.37, 0.39, 0.38, 0.37, 0.39,\n",
      "0.41, 0.37, 0.42, 0.41, 0.42, 0.39, 0.41, 0.40, 0.38, 0.40, 0.38\n",
      "Signal 3:\n",
      "• Hurst Values: 0.21, 0.25, 0.21, 0.20, 0.23, 0.22, 0.26, 0.26, 0.25, 0.23, 0.24, 0.26,\n",
      "0.22, 0.25, 0.29, 0.26, 0.25, 0.24, 0.25, 0.27, 0.23, 0.25, 0.24, 0.26, 0.24, 0.30, 0.23,\n",
      "0.28, 0.25, 0.28, 0.27, 0.25, 0.27, 0.23, 0.22, 0.23, 0.21, 0.24, 0.28\n",
      "Signal 4:\n",
      "• Hurst Values: 0.41, 0.36, 0.41, 0.32, 0.39, 0.42, 0.39, 0.40, 0.40, 0.37, 0.33, 0.42,\n",
      "0.37, 0.32, 0.34, 0.36, 0.41, 0.33, 0.42, 0.43, 0.41, 0.39, 0.40\n",
      "R/S Analysis Method\n",
      "Signal 1:\n",
      "• Hurst Values: 0.59, 0.52, 0.54, 0.55, 0.59, 0.60, 0.55, 0.53, 0.53, 0.62, 0.66, 0.58,\n",
      "0.53, 0.54, 0.53, 0.55, 0.53, 0.52, 0.57, 0.56, 0.54, 0.61, 0.62, 0.54, 0.57, 0.52, 0.56,\n",
      "0.58, 0.60, 0.56, 0.51, 0.52, 0.57, 0.57, 0.57, 0.55, 0.55, 0.52, 0.51\n",
      "Signal 2:\n",
      "• Hurst Values: 0.39, 0.39, 0.41, 0.41, 0.38, 0.38, 0.40, 0.37, 0.39, 0.38, 0.37, 0.39,\n",
      "0.41, 0.37, 0.42, 0.41, 0.42, 0.39, 0.41, 0.40, 0.38, 0.40, 0.38\n",
      "Signal 3:\n",
      "• Hurst Values: 0.21, 0.25, 0.21, 0.20, 0.23, 0.22, 0.26, 0.26, 0.25, 0.23, 0.24, 0.26,\n",
      "0.22, 0.25, 0.29, 0.26, 0.25, 0.24, 0.25, 0.27, 0.23, 0.25, 0.24, 0.26, 0.24, 0.30, 0.23,\n",
      "0.28, 0.25, 0.28, 0.27, 0.25, 0.27, 0.23, 0.22, 0.23, 0.21, 0.24, 0.28\n",
      "Signal 4:\n",
      "• Hurst Values: 0.41, 0.36, 0.41, 0.32, 0.39, 0.42, 0.39, 0.40, 0.40, 0.37, 0.33, 0.42,\n",
      "0.37, 0.32, 0.34, 0.36, 0.41, 0.33, 0.42, 0.43, 0.41, 0.39, 0.40\n",
      "13\n",
      "• For every scale, the mean of the R/S values across all segments is calculated. This\n",
      "mean yields an estimate of the fluctuation across the entire signal at the scale.\n",
      "Logarithmic Transformation:\n",
      "• The scale values and the mean rescaled range values are both transformed by using\n",
      "logarithms (log base 2). This transformation linearizes the relationship between the\n",
      "scale and the rescaled range, making it simpler to estimate the scaling exponent.\n",
      "Linear Regression:\n",
      "• A linear regression is conducted between the logarithms of the scale values and the\n",
      "logarithms of the average rescaled range values. The slope of the regression line is\n",
      "the scaling exponent, which is equivalent to the Hurst exponent.\n",
      "Hurst Exponent Calculation:\n",
      "• The Hurst exponent (H) is calculated from the slope of the regression line. The\n",
      "formula used to calculate the Hurst exponent is:\n",
      "H = slope − 1\n",
      "• If the slope minus 1 is negative, the Hurst exponent is used as the slope itself.\n",
      "• If the slope minus 1 is positive, the Hurst exponent is shifted by subtracting 1 from\n",
      "the slope.\n",
      "Output:\n",
      "• The last Hurst exponent is the result of the R/S method. This number gives a\n",
      "measure of the long-term memory or persistence of the time series. The Hurst\n",
      "exponent is usually printed and can also be written to a file for later analysis.\n",
      "10\n",
      "R/S Python Code\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from numpy.polynomial.polynomial import Polynomial\n",
      "import os\n",
      "import glob\n",
      "def calculate_hurst_exponent_rs(signal):\n",
      "N = len(signal)\n",
      "# Define scales\n",
      "scale_min = 16\n",
      "scale_max = N // 4\n",
      "num_scales = 20\n",
      "scale_list = np.unique(np.logspace(np.log2(scale_min), np.log2(scale_max), num=num_scales, base=2, dtype=int))\n",
      "RS = []\n",
      "for scale in scale_list:\n",
      "if N // scale < 2:\n",
      "continue\n",
      "rs_values = []\n",
      "for start in range(0, N - scale + 1, scale):\n",
      "segment = signal[start:start+scale]\n",
      "mean_seg = np.mean(segment)\n",
      "Y = np.cumsum(segment - mean_seg)\n",
      "R = np.max(Y) - np.min(Y)\n",
      "S = np.std(segment, ddof=1)\n",
      "if S != 0:\n",
      "rs_values.append(R / S)\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "result=retriever.invoke(\"what is hurst exponent\")\n",
    "for i in result:\n",
    "    print(i.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainVenv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
